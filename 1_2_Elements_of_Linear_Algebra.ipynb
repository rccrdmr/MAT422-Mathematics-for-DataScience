{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPchO6hBMV0OxQGsficuSXM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rccrdmr/MAT422-Mathematics-for-DataScience/blob/main/1_2_Elements_of_Linear_Algebra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.2 Elements of Linear Algebra\n",
        "_______________________________\n",
        "###Topics:\n",
        "* 1.2.1. Linear spaces\n",
        "* 1.2.2. Orthogonality\n",
        "* 1.2.3. Gram–Schmidt process\n",
        "* 1.2.4. Eigenvalues and eigenvectors"
      ],
      "metadata": {
        "id": "FSAeUsc7QeRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "udcJRpdK100g"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2.1. Linear Spaces\n"
      ],
      "metadata": {
        "id": "xLxxeNliUyNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.2.1.1 Linear Combinations"
      ],
      "metadata": {
        "id": "ipqs5z8pYYu0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition (Linear Combination):**\n",
        "A linear combination of vectors ${v_1},{v_2}, \\dots,{v_n}$ is an expression of the form:\n",
        "\n",
        "$$\n",
        "{v} = \\alpha_1{v_1} + \\alpha_2{v_2} + \\dots + \\alpha_n{v_n}\n",
        "$$\n",
        "\n",
        "where $\\alpha_1, \\alpha_2, \\dots, \\alpha_n$ are scalars.\n"
      ],
      "metadata": {
        "id": "x4ygKyKXYpYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectors\n",
        "v1 = np.array([1, 2])\n",
        "v2 = np.array([3, 4])\n",
        "\n",
        "# Scalars\n",
        "alpha1 = 2\n",
        "alpha2 = 3\n",
        "\n",
        "# Linear combination\n",
        "v = alpha1 * v1 + alpha2 * v2\n",
        "\n",
        "print(f\"Linear combination v = {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4aFX4SX145r",
        "outputId": "3d266fb4-e7b7-45cd-a5a7-40d4e34f86ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear combination v = [11 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition (Linear Subspace):**  \n",
        "A linear subspace of $V$ is a subset $U \\subseteq V$ that is closed under vector addition and scalar multiplication. That is, for all $u_1, u_2 \\in U$ and $\\alpha \\in \\mathbb{R}$, it holds that:\n",
        "$$\n",
        "u_1 + u_2 \\in U, \\quad \\text{and} \\quad \\alpha u_1 \\in U\n",
        "$$\n",
        "In particular, $0$ is always in a linear subspace. A span of a set of vectors is a linear subspace.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Xb8ehE1zML8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition (Span):**  \n",
        "Let $w_1, \\dots, w_m \\in V$. The span of $\\{w_1, \\dots, w_m\\}$, denoted $\\text{span}(w_1, \\dots, w_m)$, is the set of all linear combinations of the $w_j$'s. That is,\n",
        "$$\n",
        "\\text{span}(w_1, \\dots, w_m) = \\left\\{ \\sum_{j=1}^{m} \\alpha_j w_j : \\alpha_1, \\dots, \\alpha_m \\in \\mathbb{R} \\right\\}\n",
        "$$\n",
        "A list of vectors that span a linear subspace $U$ is also referred to as a spanning set of $U$."
      ],
      "metadata": {
        "id": "cUPSKLcsNZIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u1 = np.array([1, 2, 3])\n",
        "u2 = np.array([4, 5, 6])\n",
        "u3 = np.array([7, 8, 9])\n",
        "\n",
        "U = np.array([u1, u2]).T\n",
        "\n",
        "# Check if u3 is in the subspace spanned by u1 and u2\n",
        "coeffs, residuals, rank, s = np.linalg.lstsq(U, u3, rcond=None)\n",
        "\n",
        "if np.allclose(np.dot(U, coeffs), u3):\n",
        "    print(f\"u3 is in the subspace spanned by u1 and u2. Coefficients: {coeffs}\")\n",
        "else:\n",
        "    print(\"u3 is not in the subspace spanned by u1 and u2.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_GhCw5r3B13",
        "outputId": "ac503643-0543-41e7-d988-de7ebabfa905"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "u3 is in the subspace spanned by u1 and u2. Coefficients: [-1.  2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemma (Every Span is a Linear Subspace):**  \n",
        "Let $W = \\text{span}(w_1, \\dots, w_m)$. Then $W$ is a linear subspace."
      ],
      "metadata": {
        "id": "iJNYxFOHNav1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "v1 = np.array([1, 2, 3])\n",
        "v2 = np.array([4, 5, 6])\n",
        "alpha1, alpha2 = 2, -1\n",
        "\n",
        "v = alpha1 * v1 + alpha2 * v2\n",
        "print(f\"Linear Combination v = {v}\")\n",
        "\n",
        "u = np.array([5, 6, 7])\n",
        "\n",
        "# Check if u is in the span (v1, v2)\n",
        "try:\n",
        "    coeffs = np.linalg.solve(np.array([v1, v2]).T, u)\n",
        "    print(f\"Vector u is in the span: u = {coeffs[0]}*v1 + {coeffs[1]}*v2\")\n",
        "except np.linalg.LinAlgError:\n",
        "    print(\"Vector u is not in the span of v1 and v2\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2Uihx4O1wDv",
        "outputId": "7fbc32ae-6262-49cc-fd07-44b2f5094178"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Combination v = [-2 -1  0]\n",
            "Vector u is not in the span of v1 and v2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.2.1.2 Linear Independence and Dimension"
      ],
      "metadata": {
        "id": "tS3YAmlnbL02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition (Linear Independence):**  \n",
        "A list of vectors $u_1, \\dots, u_m$ is **linearly independent** if none of them can be written as a linear combination of the others. Formally, this means:\n",
        "$$\n",
        "\\forall i, \\quad u_i \\notin \\text{span}(\\{u_j : j \\neq i\\})\n",
        "$$\n",
        "If a list of vectors is not linearly independent, it is called **linearly dependent**.\n"
      ],
      "metadata": {
        "id": "GfBXelcwRad2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u1 = np.array([1, 2, 3])\n",
        "u2 = np.array([4, 5, 6])\n",
        "u3 = np.array([7, 8, 9])\n",
        "\n",
        "matrix = np.array([u1, u2, u3]).T\n",
        "\n",
        "# Check for linear independence by calculating the rank\n",
        "rank = np.linalg.matrix_rank(matrix)\n",
        "\n",
        "if rank == matrix.shape[1]:\n",
        "    print(\"The vectors are linearly independent.\")\n",
        "else:\n",
        "    print(\"The vectors are linearly dependent.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in-LHU-T56fj",
        "outputId": "db573d6a-0441-4b4f-835b-34359bbf9372"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vectors are linearly dependent.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemma (Linear Independence Condition):**  \n",
        "The vectors $u_1, \\dots, u_m$ are linearly independent if and only if:\n",
        "$$\n",
        "\\sum_{j=1}^{m} \\alpha_j u_j = 0 \\implies \\alpha_j = 0, \\forall j\n",
        "$$\n",
        "Equivalently, $u_1, \\dots, u_m$ are linearly dependent if and only if there exist $\\alpha_j$'s, not all zero, such that:\n",
        "$$\n",
        "\\sum_{j=1}^{m} \\alpha_j u_j = 0\n",
        "$$"
      ],
      "metadata": {
        "id": "V8G6I9B3RfFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u1 = np.array([1, 0, 0])\n",
        "u2 = np.array([0, 1, 0])\n",
        "u3 = np.array([0, 0, 1])\n",
        "\n",
        "matrix = np.array([u1, u2, u3]).T\n",
        "\n",
        "# Solve the equation α1*u1 + α2*u2 + α3*u3 = 0\n",
        "coeffs, residuals, rank, s = np.linalg.lstsq(matrix, np.zeros(len(u1)), rcond=None)\n",
        "\n",
        "if np.allclose(coeffs, 0):\n",
        "    print(\"The only solution is the trivial one: α1 = α2 = α3 = 0. The vectors are linearly independent.\")\n",
        "else:\n",
        "    print(\"There exists a non-trivial solution. The vectors are linearly dependent.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9FdSigv4vOB",
        "outputId": "d2bf9bfa-fbf9-4d19-b1e2-e2e10576ad69"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The only solution is the trivial one: α1 = α2 = α3 = 0. The vectors are linearly independent.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition (Basis of a Space):**  \n",
        "Let $U$ be a linear subspace of $V$. A basis of $U$ is a list of vectors $u_1, \\dots, u_m$ in $U$ that:\n",
        "1. Span $U$, that is, $U = \\text{span}(u_1, \\dots, u_m)$; and\n",
        "2. Are linearly independent."
      ],
      "metadata": {
        "id": "KgVbgm22Rv0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v1 = np.array([1, 0, 0])\n",
        "v2 = np.array([0, 1, 0])\n",
        "v3 = np.array([0, 0, 1])\n",
        "\n",
        "matrix = np.array([v1, v2, v3])\n",
        "\n",
        "# Calculate the rank of the matrix\n",
        "rank = np.linalg.matrix_rank(matrix)\n",
        "\n",
        "# Check if they form a basis\n",
        "if rank == 3:\n",
        "    print(f\"The vectors form a basis for R^3 and span a space of dimension {rank}.\")\n",
        "else:\n",
        "    print(f\"The vectors do not form a basis. They span a space of dimension {rank}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoDwWNjs3pak",
        "outputId": "257e906d-0bc5-4231-f02d-22d5be7ec3d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vectors form a basis for R^3 and span a space of dimension 3.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Theorem (Dimension Theorem):**  \n",
        "Let $U$ be a linear subspace of $V$. Any basis of $U$ always has the same number of elements. All bases of $U$ have the same length, that is, the same number of elements. We call this number the dimension of $U$ and denote it $\\text{dim}(U)$.\n"
      ],
      "metadata": {
        "id": "NjpM_VwyRwj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define two sets of basis vectors for a subspace of R^3\n",
        "basis1 = np.array([[1, 0, 0], [0, 1, 0]])  # Set 1\n",
        "basis2 = np.array([[1, 1, 0], [-1, 1, 0]]) # Set 2\n",
        "\n",
        "# Calculate the ranks\n",
        "rank1 = np.linalg.matrix_rank(basis1)\n",
        "rank2 = np.linalg.matrix_rank(basis2)\n",
        "\n",
        "if rank1 == rank2:\n",
        "    print(f\"Both sets form a basis for a subspace of dimension {rank1}.\")\n",
        "else:\n",
        "    print(\"The bases do not span the same dimension.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsxC3EqE5c4r",
        "outputId": "441d8a31-05b2-4e28-fdc1-ee43b2c85e44"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Both sets form a basis for a subspace of dimension 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemma (Characterization of Linearly Dependent Sets):**  \n",
        "Let $u_1, \\dots, u_m$ be a linearly dependent list of vectors with a linearly independent subset $u_i$, $i \\in \\{1, \\dots, k\\}, k < m$. Then there is an $i > k$ such that:\n",
        "1. $u_i \\in \\text{span}(u_1, \\dots, u_{i-1})$\n",
        "2. $\\text{span}(\\{u_j : j \\in \\{1, \\dots, m\\}\\}) = \\text{span}(\\{u_j : j \\in \\{1, \\dots, m\\}, j \\neq i\\})$\n"
      ],
      "metadata": {
        "id": "99HKF4lqRgyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u1 = np.array([1, 2, 3])\n",
        "u2 = np.array([2, 4, 6])\n",
        "u3 = np.array([3, 6, 9])\n",
        "\n",
        "# Check if any vector can be expressed as a linear combination of the others\n",
        "matrix = np.array([u1, u2]).T\n",
        "coeffs, residuals, rank, s = np.linalg.lstsq(matrix, u3, rcond=None)\n",
        "\n",
        "if np.allclose(np.dot(matrix, coeffs), u3):\n",
        "    print(f\"Vector u3 can be written as a linear combination: u3 = {coeffs[0]}*u1 + {coeffs[1]}*u2\")\n",
        "else:\n",
        "    print(\"No vector can be expressed as a linear combination of the others.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxPS2Afx5uL6",
        "outputId": "4428918b-0747-4cdc-c1d7-e0831d39cc86"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector u3 can be written as a linear combination: u3 = 0.5999999999999998*u1 + 1.2000000000000002*u2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2.2. Orthogonality\n"
      ],
      "metadata": {
        "id": "gh-kYupscB7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.2.1 Orthonormal Bases"
      ],
      "metadata": {
        "id": "xPMbo8egzEZ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition (Norm and Inner Product):**  \n",
        "The **inner product** of two vectors $u, v \\in \\mathbb{R}^n$ is defined as:\n",
        "$$\n",
        "\\langle u, v \\rangle = u \\cdot v = \\sum_{i=1}^{n} u_i v_i\n",
        "$$\n",
        "The **norm** of a vector $u$ is defined as:\n",
        "$$\\|u\\| = \\sqrt{\\sum_{i=1}^{n} u_i^2}$$"
      ],
      "metadata": {
        "id": "dGanowhOSX6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u = np.array([1, 2, 3])\n",
        "v = np.array([4, 5, 6])\n",
        "\n",
        "# Calculate the inner product ⟨u, v⟩\n",
        "inner_product = np.dot(u, v)\n",
        "\n",
        "# Calculate the norm ‖u‖\n",
        "norm_u = np.linalg.norm(u)\n",
        "\n",
        "print(f\"Inner product ⟨u, v⟩ = {inner_product}\")\n",
        "print(f\"Norm ‖u‖ = {norm_u}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6gfFoTFBhWl",
        "outputId": "a0959235-f6c7-42d2-d450-a6498e5b5a1e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inner product ⟨u, v⟩ = 32\n",
            "Norm ‖u‖ = 3.7416573867739413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition (Orthonormal Bases):**  \n",
        "A list of vectors $\\{u_1, \\dots, u_m\\}$ is **orthonormal** if the $u_i$’s are pairwise orthogonal and each has norm 1. That is, for all $i$ and all $j \\neq i$:\n",
        "$$\n",
        "\\langle u_i, u_j \\rangle = 0, \\quad \\text{and} \\quad \\|u_i\\| = 1\n",
        "$$"
      ],
      "metadata": {
        "id": "IqsQMRBTS2Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u1 = np.array([1, 0, 0])\n",
        "u2 = np.array([0, 1, 0])\n",
        "u3 = np.array([0, 0, 1])\n",
        "\n",
        "def is_orthonormal(vectors):\n",
        "    for i in range(len(vectors)):\n",
        "        for j in range(len(vectors)):\n",
        "            inner_product = np.dot(vectors[i], vectors[j])\n",
        "            if i == j and not np.isclose(inner_product, 1):\n",
        "                return False\n",
        "            elif i != j and not np.isclose(inner_product, 0):\n",
        "                return False\n",
        "    return True\n",
        "\n",
        "# Check if {u1, u2, u3} is orthonormal\n",
        "vectors = [u1, u2, u3]\n",
        "if is_orthonormal(vectors):\n",
        "    print(\"The vectors are orthonormal.\")\n",
        "else:\n",
        "    print(\"The vectors are not orthonormal.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfzp3Lh4BpWt",
        "outputId": "6a6666f9-b3e8-4f0c-c5ef-8356f824e0a6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vectors are orthonormal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemma:**  \n",
        "Let $\\{u_1, \\dots, u_m\\}$ be an orthonormal list of vectors.\n",
        "\n",
        "1. The norm of any linear combination of these vectors satisfies:\n",
        "$$\n",
        "\\left\\|\\sum_{j=1}^{m} \\alpha_j u_j \\right\\|^2 = \\sum_{j=1}^{m} \\alpha_j^2\n",
        "$$\n",
        "2. The vectors $\\{u_1, \\dots, u_m\\}$ are linearly independent.\n"
      ],
      "metadata": {
        "id": "BCczZsqrSYjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.2.2.2 Best Approximation Theorem\n"
      ],
      "metadata": {
        "id": "dOSyaWBKzVh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Theorem (Best Approximation Theorem):**  \n",
        "Let $U \\subseteq V$ be a linear subspace with an orthonormal basis $q_1, \\dots, q_m$ and let $v \\in V$. For any $u \\in U$:\n",
        "$$\n",
        "\\|v - P_U v\\| \\leq \\|v - u\\|\n",
        "$$\n",
        "Furthermore, if $u \\in U$ and the inequality above is an equality, then $u = P_U v$.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VYMM0OlbFozg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the orthonormal basis for subspace U\n",
        "q1 = np.array([1, 0])\n",
        "q2 = np.array([0, 1])\n",
        "\n",
        "v = np.array([3, 4])\n",
        "u = np.array([1, 2])\n",
        "\n",
        "# orthogonal projection P_U v\n",
        "PU_v = np.dot(v, q1) * q1 + np.dot(v, q2) * q2\n",
        "\n",
        "if np.linalg.norm(v - PU_v) <= np.linalg.norm(v - u):\n",
        "    print(\"The Best Approximation Theorem is satisfied.\")\n",
        "else:\n",
        "    print(\"The Best Approximation Theorem is not satisfied.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StANn3zTDLLJ",
        "outputId": "e56976bf-d69d-4489-b62d-19e4a3aec4b2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Best Approximation Theorem is satisfied.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition (Orthogonal Projection):**  \n",
        "Let $U \\subseteq V$ be a linear subspace with an orthonormal basis $q_1, \\dots, q_m$. The orthogonal projection of $v \\in V$ on $U$ is defined as:\n",
        "$$\n",
        "P_U v = \\sum_{j=1}^{m} \\langle v, q_j \\rangle q_j\n",
        "$$\n"
      ],
      "metadata": {
        "id": "qWvxtYnNXMj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = np.array([1, 0])\n",
        "q2 = np.array([0, 1])\n",
        "\n",
        "v = np.array([3, 4])\n",
        "\n",
        "PU_v = np.dot(v, q1) * q1 + np.dot(v, q2) * q2\n",
        "\n",
        "print(f\"Orthogonal projection P_U v = {PU_v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlD-Dkq5DhoG",
        "outputId": "344660fc-305d-4ddf-9263-118196cba62f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orthogonal projection P_U v = [3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemma (Pythagorean Theorem):**  \n",
        "Let $u, v \\in V$ be orthogonal. Then:\n",
        "$$\n",
        "\\|u + v\\|^2 = \\|u\\|^2 + \\|v\\|^2\n",
        "$$"
      ],
      "metadata": {
        "id": "HyyHISx2Xytk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemma (Cauchy-Schwarz Inequality):**  \n",
        "For any $u, v \\in V$:\n",
        "$$\n",
        "|\\langle u, v \\rangle| \\leq \\|u\\| \\|v\\|\n",
        "$$"
      ],
      "metadata": {
        "id": "aBxkbxkUX0Cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemma (Orthogonal Decomposition):**  \n",
        "Let $U \\subseteq V$ be a linear subspace with an orthonormal basis $q_1, \\dots, q_m$ and let $v \\in V$. For any $u \\in U$:\n",
        "$$\n",
        "\\langle v - P_U v, u \\rangle = 0\n",
        "$$\n",
        "In particular, $v$ can be decomposed as $(v - P_U v) + P_U v$, where the two terms are orthogonal.\n"
      ],
      "metadata": {
        "id": "eZgrKrrXX2Nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = np.array([1, 0])\n",
        "q2 = np.array([0, 1])\n",
        "\n",
        "v = np.array([3, 4])\n",
        "\n",
        "PU_v = np.dot(v, q1) * q1 + np.dot(v, q2) * q2\n",
        "\n",
        "orthogonal_complement = v - PU_v\n",
        "\n",
        "# Verify that ⟨v - P_U v, u⟩ = 0 for all u in U\n",
        "for q in [q1, q2]:\n",
        "    if np.isclose(np.dot(orthogonal_complement, q), 0):\n",
        "        print(f\"The vector {orthogonal_complement} is orthogonal to {q}.\")\n",
        "    else:\n",
        "        print(f\"The vector {orthogonal_complement} is not orthogonal to {q}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b683LBifD7XW",
        "outputId": "2b3bbade-fac0-41ab-d96b-2e915ccd05c6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vector [0 0] is orthogonal to [1 0].\n",
            "The vector [0 0] is orthogonal to [0 1].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2.3 Gram-Schmidt Process\n"
      ],
      "metadata": {
        "id": "6fdSOXG3zkqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Theorem (Gram-Schmidt Process):**  \n",
        "Let $a_1, \\dots, a_m $ in $\\mathbb{R}^n$ be linearly independent. Then there exists an orthonormal basis $q_1, \\dots, q_m$ of the span $ \\text{span}(a_1, \\dots, a_m)$.\n",
        "\n",
        "The orthonormal basis is constructed as follows:\n",
        "$$\n",
        "q_1 = \\frac{a_1}{\\|a_1\\|}, \\quad\n",
        "q_i = \\frac{a_i - \\sum_{j=1}^{i-1} \\langle a_i, q_j \\rangle q_j}{\\|a_i - \\sum_{j=1}^{i-1} \\langle a_i, q_j \\rangle q_j\\|} \\text{ for } i = 2, \\dots, m.\n",
        "$$"
      ],
      "metadata": {
        "id": "xIAdmeE9IWYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gram_schmidt(A):\n",
        "    \"\"\"Applies the Gram-Schmidt process to the columns of matrix A.\"\"\"\n",
        "    Q = np.zeros_like(A)  # Q with same shape as A\n",
        "\n",
        "    for i in range(A.shape[1]):\n",
        "        q_i = A[:, i]  # Start with current vector a_i\n",
        "\n",
        "        for j in range(i):\n",
        "            q_i -= np.dot(A[:, i], Q[:, j]) * Q[:, j]  # Subtract projections onto previously computed q_j\n",
        "\n",
        "        Q[:, i] = q_i / np.linalg.norm(q_i)  # Normalize q_i to get the orthonormal vector\n",
        "\n",
        "    return Q\n",
        "\n",
        "# Example:\n",
        "a1 = np.array([1.0, 1.0, 0.0])\n",
        "a2 = np.array([1.0, 0.0, 1.0])\n",
        "a3 = np.array([0.0, 1.0, 1.0])\n",
        "A = np.column_stack([a1, a2, a3])\n",
        "\n",
        "Q = gram_schmidt(A)\n",
        "\n",
        "print(\"Orthonormal basis Q:\")\n",
        "print(Q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSuUpbfKHE5j",
        "outputId": "ea727e0f-e919-42d6-f0ce-b25720a6b3ee"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orthonormal basis Q:\n",
            "[[ 0.70710678  0.40824829 -0.57735027]\n",
            " [ 0.70710678 -0.40824829  0.57735027]\n",
            " [ 0.          0.81649658  0.57735027]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2.4 Eigenvalues and Eigenvectors"
      ],
      "metadata": {
        "id": "VUkc1diN-mmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition (Eigenvalues and Eigenvectors):**  \n",
        "Let $A \\in \\mathbb{R}^{d \\times d}$ be a square matrix. Then $\\lambda \\in \\mathbb{R}$ is an eigenvalue of $A$ if there exists a nonzero vector $x \\neq 0$ such that\n",
        "\n",
        "$$\n",
        "A x = \\lambda x.\n",
        "$$\n",
        "\n",
        "The vector $x$ is referred to as an eigenvector."
      ],
      "metadata": {
        "id": "pdnvKNH7yR3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemma (Number of Eigenvalues):**  \n",
        "Let $ A \\in \\mathbb{R}^{d \\times d} $ and let $ \\lambda_1, \\dots, \\lambda_m $ be distinct eigenvalues of $ A $ with corresponding nonzero eigenvectors $ x_1, \\dots, x_m $. Then $ x_1, \\dots, x_m $ are linearly independent. As a result, $ m \\leq d $.\n"
      ],
      "metadata": {
        "id": "_KRzRv1izJY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[4, 1],\n",
        "              [2, 3]])\n",
        "\n",
        "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
        "\n",
        "print(\"Eigenvalues of A:\", eigenvalues)\n",
        "print(\"Eigenvectors of A:\")\n",
        "print(eigenvectors)\n",
        "\n",
        "# Check if eigenvectors are linearly independent\n",
        "rank = np.linalg.matrix_rank(eigenvectors)\n",
        "\n",
        "if rank == eigenvectors.shape[1]:\n",
        "    print(\"The eigenvectors are linearly independent.\")\n",
        "else:\n",
        "    print(\"The eigenvectors are not linearly independent.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndc318ib0vP8",
        "outputId": "ad1743f9-bd8e-40af-a79e-9bfaa84f6c35"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvalues of A: [5. 2.]\n",
            "Eigenvectors of A:\n",
            "[[ 0.70710678 -0.4472136 ]\n",
            " [ 0.70710678  0.89442719]]\n",
            "The eigenvectors are linearly independent.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.2.4.1 Diagonalization of Symmetric Matrices"
      ],
      "metadata": {
        "id": "GOCVXFxs0GEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition:**\n",
        "\\\n",
        "A symmetric matrix $A$ is **diagonalizable**, meaning it can be written in the form:\n",
        "\n",
        "$$\n",
        "A = PDP^{-1}\n",
        "$$\n",
        "\n",
        "where $P$ is an orthogonal matrix (i.e., $P^{-1} = P^T$), and $D$ is a diagonal matrix containing the eigenvalues of $A$. Symmetric matrices have real eigenvalues, and their eigenvectors are orthogonal."
      ],
      "metadata": {
        "id": "QmZ4U9N70VcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Symmetric matrix\n",
        "A = np.array([[4, 1, 1],\n",
        "              [1, 4, 1],\n",
        "              [1, 1, 4]])\n",
        "\n",
        "eigenvalues, eigenvectors = np.linalg.eigh(A)\n",
        "\n",
        "# eigenvalues -> diagonal matrix D\n",
        "D = np.diag(eigenvalues)\n",
        "\n",
        "# eigenvectors -> matrix P\n",
        "P = eigenvectors\n",
        "\n",
        "# Check if A = PDP^T\n",
        "A_reconstructed = P @ D @ P.T\n",
        "\n",
        "print(\"Original matrix A:\")\n",
        "print(A)\n",
        "print(\"Reconstructed matrix A from PDP^T:\")\n",
        "print(A_reconstructed)\n",
        "\n",
        "if np.allclose(A, A_reconstructed):\n",
        "    print(\"The matrix A is diagonalizable as A = PDP^T.\")\n",
        "else:\n",
        "    print(\"The matrix A is not diagonalizable in the form A = PDP^T.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNSHdO1QJbdz",
        "outputId": "68005e64-18ec-4d2c-b667-a9fe6638246e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original matrix A:\n",
            "[[4 1 1]\n",
            " [1 4 1]\n",
            " [1 1 4]]\n",
            "Reconstructed matrix A from PDP^T:\n",
            "[[4. 1. 1.]\n",
            " [1. 4. 1.]\n",
            " [1. 1. 4.]]\n",
            "The matrix A is diagonalizable as A = PDP^T.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Theorem (Diagonalization of Symmetric Matrices):**  \n",
        "If $ A $ is symmetric, then any two eigenvectors from different eigenspaces are orthogonal.\n"
      ],
      "metadata": {
        "id": "-pQVzpV3zfwy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Theorem (The Spectral Theorem for Symmetric Matrices):**  \n",
        "An $ n \\times n $ symmetric matrix $ A $ has the following properties:\n",
        "- $ A $ has $ n $ real eigenvalues, counting multiplicities.\n",
        "- If $ \\lambda $ is an eigenvalue of $ A $ with multiplicity $ k $, then the eigenspace for $ \\lambda $ is $ k $-dimensional.\n",
        "- The eigenspaces are mutually orthogonal, in the sense that eigenvectors corresponding to different eigenvalues are orthogonal.\n",
        "- $ A $ is orthogonally diagonalizable."
      ],
      "metadata": {
        "id": "_zLCE9n7zrBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1.2.4.2 Constrained Optimization"
      ],
      "metadata": {
        "id": "cLWp68qK_UJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Theorem (Constrained Optimization):**  \n",
        "Let $ A $ be an $ n \\times n $ symmetric matrix with an orthogonal diagonalization $ A = P D P^{-1} $. The columns of $ P $ are orthonormal eigenvectors $ v_1, \\dots, v_n $ of $ A $. Assume that the diagonal of $ D $ is arranged so that $ \\lambda_1 \\leq \\lambda_2 \\leq \\dots \\leq \\lambda_n $. Then:\n",
        "\n",
        "$$\n",
        "\\min_{x \\neq 0} \\frac{x^T A x}{x^T x} = \\lambda_1\n",
        "$$\n",
        "\n",
        "is achieved when $ x = v_1 $, and\n",
        "\n",
        "$$\n",
        "\\max_{x \\neq 0} \\frac{x^T A x}{x^T x} = \\lambda_n\n",
        "$$\n",
        "\n",
        "is achieved when $ x = v_n $.\n"
      ],
      "metadata": {
        "id": "rgmLSqvl1GXy"
      }
    }
  ]
}